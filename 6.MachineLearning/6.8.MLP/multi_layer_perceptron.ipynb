{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(dataset):\n",
    "    Y = dataset['label'].values\n",
    "    Y = np.eye(10)[Y] #one hot\n",
    "    \n",
    "    X = dataset.drop('label', axis=1).values\n",
    "    X[X < 127] = 0\n",
    "    X[X >= 127] = 1\n",
    "\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = pd.read_csv(\"mnist_train.csv\")\n",
    "X_train, Y_train = preprocess(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "test_dataset = pd.read_csv(\"mnist_test.csv\")\n",
    "X_test, Y_test = preprocess(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(X):\n",
    "    exps = np.exp(X)\n",
    "    return exps / np.sum(exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in = X_train.shape[1]\n",
    "H1 = 65\n",
    "H2 = 15\n",
    "D_out = Y_train.shape[1]\n",
    "\n",
    "η = 0.001\n",
    "epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 , W2 , W3 = np.random.randn(D_in, H1), np.random.randn(H1, H2), np.random.randn(H2, D_out)\n",
    "B1 , B2 , B3 = np.random.randn(H1) , np.random.randn(H2) , np.random.randn(D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    Y_hat = []\n",
    "    for x, y in zip(X_test, Y_test):\n",
    "\n",
    "        # forward\n",
    "        x = x.reshape(-1, 1)\n",
    "        net1 = x.T @ W1 + B1\n",
    "        out1 = sigmoid(net1)\n",
    "\n",
    "        net2 = out1 @ W2 + B2\n",
    "        out2 = sigmoid(net2)\n",
    "\n",
    "        net3 = out2 @ W3 + B3\n",
    "        out3 = net3\n",
    "        y_hat = softmax(out3)\n",
    "        Y_hat.append(y_hat.T)\n",
    "\n",
    "    acc = np.mean(np.argmax(y_hat) == np.argmax(y))\n",
    "\n",
    "    Y_hat = np.array(Y_hat).reshape(-1, 10)\n",
    "    loss = np.sum(-np.sum(np.multiply(Y_train, np.log10(Y_hat))))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 43336.862285956224 acc: 0.635\n",
      "loss: 24767.78224841616 acc: 0.7423\n",
      "loss: 19535.30133986915 acc: 0.7892\n",
      "loss: 16778.391219606332 acc: 0.8144\n",
      "loss: 15026.073646438233 acc: 0.833\n",
      "loss: 13785.65922308665 acc: 0.8434\n",
      "loss: 12841.529705157518 acc: 0.8503\n",
      "loss: 12088.596924921303 acc: 0.8569\n",
      "loss: 11469.734321682881 acc: 0.8608\n",
      "loss: 10949.11734684017 acc: 0.8661\n",
      "loss: 10501.832914677298 acc: 0.8703\n",
      "loss: 10111.187649131349 acc: 0.8734\n",
      "loss: 9765.267583963338 acc: 0.8764\n",
      "loss: 9454.822196364858 acc: 0.8783\n",
      "loss: 9173.251661109536 acc: 0.88\n",
      "loss: 8916.038673849183 acc: 0.8835\n",
      "loss: 8679.768325656987 acc: 0.8877\n",
      "loss: 8461.55969722198 acc: 0.89\n",
      "loss: 8258.980164343642 acc: 0.892\n",
      "loss: 8070.004056355115 acc: 0.8944\n",
      "loss: 7892.962433265421 acc: 0.8967\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 45\u001b[0m\n\u001b[0;32m     43\u001b[0m     B1 \u001b[39m=\u001b[39m B1 \u001b[39m-\u001b[39m η \u001b[39m*\u001b[39m grad_B1\n\u001b[0;32m     44\u001b[0m     B2 \u001b[39m=\u001b[39m B2 \u001b[39m-\u001b[39m η \u001b[39m*\u001b[39m grad_B2\n\u001b[1;32m---> 45\u001b[0m     B3 \u001b[39m=\u001b[39m B3 \u001b[39m-\u001b[39m η \u001b[39m*\u001b[39m grad_B3\n\u001b[0;32m     47\u001b[0m Y_hat \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(Y_hat)\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m10\u001b[39m)\n\u001b[0;32m     48\u001b[0m loss \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(\u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39mmultiply(Y_train, np\u001b[39m.\u001b[39mlog10(Y_hat))))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    Y_hat = []\n",
    "    for x, y in zip(X_train, Y_train):\n",
    "\n",
    "        # forward\n",
    "        x = x.reshape(-1, 1)\n",
    "        net1 = x.T @ W1 + B1\n",
    "        out1 = sigmoid(net1)\n",
    "\n",
    "        net2 = out1 @ W2 + B2\n",
    "        out2 = sigmoid(net2)\n",
    "\n",
    "        net3 = out2 @ W3 + B3\n",
    "        out3 = net3\n",
    "        y_hat = softmax(out3)\n",
    "\n",
    "        Y_hat.append(y_hat.T)\n",
    "\n",
    "        # back propagation\n",
    "        \n",
    "        error = -2 * (y - y_hat)\n",
    "        grad_W3 = out2.T @ error\n",
    "        grad_B3 = error\n",
    "\n",
    "        error = error @ W3.T * out2 * (1 - out2)\n",
    "        grad_W2 = out1.T @ error\n",
    "        grad_B2 = error\n",
    "\n",
    "        error = error @ W2.T * out1 * (1 - out1)\n",
    "        grad_W1 = x @ error\n",
    "        grad_B1 = error\n",
    "\n",
    "        # update\n",
    "\n",
    "        W1 = W1 - η * grad_W1\n",
    "        W2 = W2 - η * grad_W2\n",
    "        W3 = W3 - η * grad_W3\n",
    "\n",
    "        B1 = B1 - η * grad_B1\n",
    "        B2 = B2 - η * grad_B2\n",
    "        B3 = B3 - η * grad_B3\n",
    "    \n",
    "    Y_hat = np.array(Y_hat).reshape(-1, 10)\n",
    "    loss = np.sum(-np.sum(np.multiply(Y_train, np.log10(Y_hat))))\n",
    "    print('loss:', loss, 'acc:', test())\n",
    "    \n",
    "print('train completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

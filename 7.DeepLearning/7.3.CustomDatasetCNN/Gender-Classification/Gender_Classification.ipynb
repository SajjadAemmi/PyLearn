{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gender_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wbrvEmvL0PL"
      },
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CUeMshlM4Jx"
      },
      "source": [
        "!kaggle datasets list -s \"Gender Classification 200K Images | CelebA\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqCFJ3O5Q5Up"
      },
      "source": [
        "!kaggle datasets download -d ashishjangra27/gender-recognition-200k-images-celeba"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jgPy2o1U5PY"
      },
      "source": [
        "!unzip -qq gender-recognition-200k-images-celeba.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gyr5TQBtGQ_D"
      },
      "source": [
        "import os\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bBHqR7VGWoC"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   rotation_range=40,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(\"Dataset/Train/\",\n",
        "                                               batch_size=256,\n",
        "                                               shuffle=True,\n",
        "                                               class_mode='binary', \n",
        "                                               target_size=(64, 64))     \n",
        "\n",
        "validation_data = test_datagen.flow_from_directory(\"Dataset/Validation/\",\n",
        "                                                   batch_size=256,\n",
        "                                                   shuffle=True,\n",
        "                                                   class_mode='binary',\n",
        "                                                   target_size=(64, 64))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn801O2HGZo5"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "model = tf.keras.models.Sequential([\n",
        "    # 1st conv\n",
        "    tf.keras.layers.Conv2D(96, (11,11), strides=(4,4), activation='relu', input_shape=(64, 64, 3)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2, strides=(2,2)),\n",
        "    # 2nd conv\n",
        "    tf.keras.layers.Conv2D(256, (11,11),strides=(1,1), activation='relu',padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    # 3rd conv\n",
        "    tf.keras.layers.Conv2D(384, (3,3),strides=(1,1), activation='relu',padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    # 4th conv\n",
        "    tf.keras.layers.Conv2D(384, (3,3),strides=(1,1), activation='relu',padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    # 5th Conv\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), strides=(1, 1), activation='relu',padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2, strides=(2, 2)),\n",
        "    # To Flatten layer\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # To FC layer 1\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    #To FC layer 2\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MdhdHr2cm_9"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=Adam(lr=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUlPTR5Vckrf"
      },
      "source": [
        "hist = model.fit(train_data,\n",
        "                 validation_data=validation_data,\n",
        "                 steps_per_epoch=256,\n",
        "                 validation_steps=256,\n",
        "                 epochs=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sROM4B6cGfk2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = hist.history['accuracy']\n",
        "val_acc = hist.history['val_accuracy']\n",
        "loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNXIDGIdGioP"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "from keras.preprocessing import image\n",
        "# predicting images\n",
        "path = \"Dataset/Test/Male/160002.jpg\"\n",
        "img = image.load_img(path, target_size=(64, 64))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "\n",
        "images = np.vstack([x])\n",
        "classes = model.predict(images, batch_size=1)\n",
        "print(classes[0])\n",
        "if classes[0]>0.5:\n",
        "    print(\"is a male\")\n",
        "else:\n",
        "    print(\"is a female\")\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}